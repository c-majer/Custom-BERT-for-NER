{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECTIVE:\n",
    "    In this project I build a NER (Named Entitity Recognition) model on top of the BERT architecture.\n",
    "    The aim is to adapt the BERT Large Language Model (LLM) for a specific task.\n",
    "    Here, BertForTokenClassification is used. It is included in the Tranformers library.\n",
    "    The BertForTokenClassification has a token classification head on top, which allows to make predictions at a token level.\n",
    "    Since NER is typically a token classification problem, this architecture meets the utility requirements.\n",
    "\n",
    "METHOD:\n",
    "    The Transfer Learning method is used: \n",
    "        first pretraining a large neural network in an unsupervised way, then fine-tune that NN on the task of interest.\n",
    "    In this case, BERT is a NN pretrained on two tasks: masked language modeling and next sentence prediction.\n",
    "    So I am going to fine-tune this network on a NER dataset.\n",
    "    Since fine-tuning implies supervised learning, it is necessary to have a labeled dataset.\n",
    "\n",
    "NOTE:\n",
    "    Deep Learning can be accelerated a lot using a GPU instead of a CPU.\n",
    "    Despite that, in this project CPU is used and the following code is adapted to this setting.\n",
    "    If you want to run this notebook in a GPU runtime, make sure to adapt this scripts to your purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install the necessary libraries and import them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Conda Environment:\n",
    "        conda install conda-forge::seqeval\n",
    "        conda install anaconda::scikit-learn\n",
    "        pip install torch\n",
    "        conda install conda-forge::transformers\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camillo.g.majerczyk\\AppData\\Local\\miniconda3\\envs\\MinisteroGiustiziaLLM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import transformers,pandas,numpy,sklearn,seqeval,torch\n",
    "# from seqeval.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification # BertConfig, AutoTokenizer, AutoModelForMaskedLM\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNLOADING AND PROCESSING THE DATA\n",
    "In European Languages, Named Entity Recognition uses a specific annotation scheme which is defined at \"word level\". There are several word-level schemes, one widely used is the IOB-Tagging.\n",
    "IOB stands for \"Inside-Outside-Beginning\", meaning that each tag can be either an inside, outside or beginning tag for a word. This is used because named entities may comprise more than on word.\n",
    "\n",
    "To train a deep learning model for NER, we need a training dataset in IOB format (or other word-level foramts).\n",
    "While there exist several annotation tools to create such a dataset (e.g. Doccano), in this project I use the NER dataset form Kaggle. It already comes in IOB format.\n",
    "Go to the Kaggle webpage to download the dataset, unzip it, and upload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #      47959\n",
       "Word          1048565\n",
       "POS           1048575\n",
       "Tag           1048575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 category tags, each with a beginning and inside variant, and the outside tag.\n",
    "For sick of simplicity, let's remove \"art\", \"eve\" and \"nat\" named entities from this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
    "data = data[~data.Tag.isin(entities_to_remove)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create two dictionaries:\n",
    "    1 - The first maps individualtags to indices ; i.e. each tag to its specific indices (which is just a number)\n",
    "    2 - The second maps indices back to their individual tags; i.e. each indices (that is each number) to its specific tag.\n",
    "\n",
    "This is necessary to create the labels, since the computers work with numbers (indices).\n",
    "Fundamentally we will use these dictionaries when creating the training and the test sets.\n",
    "\n",
    "We can see that we have 10 different NER tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'I-per': 8,\n",
       " 'I-gpe': 9,\n",
       " 'I-tim': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training set, let's focus on what is a training example for NER.\n",
    "During the training, the training example is what it is provided in a sigle forward pass. Typically it is a sentence with the corresponding IOB tags, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camillo.g.majerczyk\\AppData\\Local\\Temp\\ipykernel_7384\\1315307992.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "3  Police put the number of marchers at 10,000 wh...   \n",
       "4  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
       "2                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n",
       "3                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(method='ffill')\n",
    "# create a new column \"sentence\" which groups the words by sentence \n",
    "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
    "# create a new column \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT, LET'S PREPARE THE DATASET AND THE DATALOADER.\n",
    "\n",
    "Now that data is preprocessed, we can turn it into PyTorch tensors such that we can provide it to the model.\n",
    "PyTorch tensors is the data format needed by the BERT model.\n",
    "\n",
    "Below, some variables are set which will be used during the training/evaluation process.\n",
    "NOTE: \n",
    "    Due to the computation time and resources required, here I fix some values as training/evaluation parameters. \n",
    "    Using a Cross Validation or Grid Search method, or perhaps other values, may lead to a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128 # Max number of tokens per sentece (BERT models have a limit of 512)\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10 # For Gradient Clipping in model training, prevent exploding gradients leading to a better convergence towards a good solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I import th tokenizer. \n",
    "The standard BERT tokenizer, and in general the tokenizers of the BERT models, use a \"word-piece tokenization\" mechanism.\n",
    "It means that it can split a single word in two or more pieces.\n",
    "\n",
    "Other tokenizers are based on \"word tokenization\", which allows to better exploit the IOB format.\n",
    "An example of such tokenizers is the one provided by Spacy (1 word = 1 token).\n",
    "Also, some models built on top of BERT comes with their specific tokenizers based for example on SpaCy.\n",
    "This is the case of italian-legal-BERT tokenizer, built starting from SpaCy and integrated with rules and abbreviations typical of the italian legal syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, BERT also want the data to respect some requirements:\n",
    "- special tokens at the beginning and end of each training example are required.\n",
    "- each training example must have the same length (related to the max length of the model, see the parameters set above)\n",
    "- it requires an attention mask\n",
    "- labels need to be created according to the dictionary defined above (the two maps)\n",
    "- word pieces that should be ignored have a label of -100 (that is the default ignore_index of PyTorch's CrossEntropyLoss)\n",
    "\n",
    "Below, it is defined a regular PyTorch dataset class, where also these requirements are taken care.\n",
    "The PyTorch dataset class transforms the training examples of a dataframe to PyTorch tensors (the format required for the trainign of BERT models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index] #.strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             # is_pretokenized=True,                              \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        \n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "      \n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels) \n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I use this PyTorch class to create the training and test sets in the PyTorch tensors format. I use a 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101, 23564, 21030,  2099,  4967,  2001,  9388,  1011,  6109,  2005,\n",
       "          2634,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'offset_mapping': tensor([[ 0,  0],\n",
       "         [ 0,  2],\n",
       "         [ 2,  5],\n",
       "         [ 5,  6],\n",
       "         [ 7, 11],\n",
       "         [12, 15],\n",
       "         [16, 19],\n",
       "         [19, 20],\n",
       "         [20, 22],\n",
       "         [23, 26],\n",
       "         [27, 32],\n",
       "         [33, 34],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0]]),\n",
       " 'labels': tensor([-100,    3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100], dtype=torch.int32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I check the structure of every training sample\n",
    "training_set[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       -100\n",
      "za          3\n",
      "##hee       -100\n",
      "##r         -100\n",
      "khan        -100\n",
      "was         -100\n",
      "mar         -100\n",
      "-           -100\n",
      "93          -100\n",
      "for         -100\n",
      "india       -100\n",
      ".           -100\n",
      "[SEP]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n"
     ]
    }
   ],
   "source": [
    "# Here I just verify that the input ids and the corresponding targets are correct\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "  print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define the PyTorch dataloaders.\n",
    "The DataLoader wraps an iterable around a dataset, making it easy to access data samples.\n",
    "It handles batching, shuffling, and parallel loading of data.\n",
    "DataLoader is particularly useful when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE MODEL\n",
    "As explained above, the chosen model for this task is BertForTokenClassification.\n",
    "Here I load it with the pretrained weights of \"bert-base-uncased\". \n",
    "I only need to additionally specify the number of labels, as this will determine the architecture of the classification head.\n",
    "\n",
    "NOTE:\n",
    "    Only the base layers are initialized with the pretrained weights. The token calssification head of top has just randomly initialized weights, which we need to train, together with the pretrained weights, using the training dataset.\n",
    "\n",
    "Also, if we change the training set, the number of labels (parameter \"num_labels\") that I set up here needs to be adapted to the entities of interest.\n",
    "That is, if I have a new training set with for example 9 entities corresponding to 9 (or more) tags, I need to specify this number of tags in the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BertForTokenClassification uses PyTorch's CrossEntropyLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "input_ids = input_ids.type(torch.LongTensor)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "attention_mask = attention_mask.type(torch.LongTensor)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "labels = labels.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=tensor(3.0202, grad_fn=<NllLossBackward0>), logits=tensor([[[ 0.2794,  0.6398,  0.1297,  ..., -0.2682,  0.0414,  0.1409],\n",
       "         [ 0.0415,  0.7419,  0.5223,  ..., -0.3782,  0.4457, -0.3592],\n",
       "         [ 0.4750,  0.0401, -0.3383,  ...,  0.4292,  0.1702, -0.0272],\n",
       "         ...,\n",
       "         [ 0.1504,  0.1827, -0.7203,  ...,  0.7097,  0.2024, -0.3951],\n",
       "         [ 0.1758,  0.1671, -0.3961,  ...,  0.3345,  0.0866, -0.0726],\n",
       "         [ 0.1751,  0.0879, -0.4160,  ...,  0.3338,  0.0757, -0.1072]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0202, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define an Optimizer.\n",
    "Here, I use the Adam optimizer with a default learning rate (meaning that the learning rate is defined a priori)\n",
    "Other optimizer are also possible and included in the Transformers repository. While the learning rate could be defined with a scheduler, for sake of computational speed I set a default LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the model and the optimizer, I can define a regular PyTorch training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].type(torch.LongTensor) \n",
    "        mask = batch['attention_mask'].type(torch.LongTensor) \n",
    "        labels = batch['labels'].type(torch.LongTensor) \n",
    "\n",
    "        output = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = output.loss.item()\n",
    "        tr_logits = output.logits\n",
    "        tr_loss += loss\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) \n",
    "        active_logits = tr_logits.view(-1, model.num_labels) \n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) \n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 \n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        output.loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the training function defined above to train the model.\n",
    "NOTE: this might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 2.376901388168335\n",
      "Training loss per 100 training steps: 1.1567911207675934\n",
      "Training loss per 100 training steps: 0.8512145508988876\n",
      "Training loss per 100 training steps: 0.7229515059891333\n",
      "Training loss per 100 training steps: 0.6294417871078686\n",
      "Training loss per 100 training steps: 0.5654549856954617\n",
      "Training loss per 100 training steps: 0.5155608908113669\n",
      "Training loss per 100 training steps: 0.47756104606712574\n",
      "Training loss per 100 training steps: 0.44931228609799817\n",
      "Training loss per 100 training steps: 0.424908483292924\n",
      "Training loss per 100 training steps: 0.40602673034785647\n",
      "Training loss per 100 training steps: 0.3858553776762818\n",
      "Training loss per 100 training steps: 0.3775639353745728\n",
      "Training loss per 100 training steps: 0.36758437941511585\n",
      "Training loss per 100 training steps: 0.3567055856187806\n",
      "Training loss per 100 training steps: 0.3457592880352711\n",
      "Training loss per 100 training steps: 0.33635113367678215\n",
      "Training loss per 100 training steps: 0.3323243203030068\n",
      "Training loss per 100 training steps: 0.32811939757048925\n",
      "Training loss per 100 training steps: 0.32727680831027167\n",
      "Training loss per 100 training steps: 0.326078961042153\n",
      "Training loss per 100 training steps: 0.32150788024433136\n",
      "Training loss per 100 training steps: 0.3173875950955139\n",
      "Training loss per 100 training steps: 0.3117590643845374\n",
      "Training loss per 100 training steps: 0.3059952403355688\n",
      "Training loss per 100 training steps: 0.30303258674482897\n",
      "Training loss per 100 training steps: 0.29986148359009085\n",
      "Training loss per 100 training steps: 0.29647916085416054\n",
      "Training loss per 100 training steps: 0.2914413832649569\n",
      "Training loss per 100 training steps: 0.28872074798566233\n",
      "Training loss per 100 training steps: 0.2856305028157981\n",
      "Training loss per 100 training steps: 0.2834465266461777\n",
      "Training loss per 100 training steps: 0.28136860345792425\n",
      "Training loss per 100 training steps: 0.27901772229450644\n",
      "Training loss per 100 training steps: 0.277137131109613\n",
      "Training loss per 100 training steps: 0.275736904947616\n",
      "Training loss per 100 training steps: 0.2722812729282602\n",
      "Training loss per 100 training steps: 0.2688245841293673\n",
      "Training loss per 100 training steps: 0.26654175351426773\n",
      "Training loss per 100 training steps: 0.2639429393601388\n",
      "Training loss per 100 training steps: 0.26131677000841114\n",
      "Training loss per 100 training steps: 0.26008954077330687\n",
      "Training loss per 100 training steps: 0.25836815232928895\n",
      "Training loss per 100 training steps: 0.25736642816060473\n",
      "Training loss per 100 training steps: 0.2565202205438718\n",
      "Training loss per 100 training steps: 0.25519606345345575\n",
      "Training loss per 100 training steps: 0.2528219108979977\n",
      "Training loss per 100 training steps: 0.2523461005054541\n",
      "Training loss per 100 training steps: 0.25151118784743287\n",
      "Training loss per 100 training steps: 0.24934201329316388\n",
      "Training loss per 100 training steps: 0.24742931959388184\n",
      "Training loss per 100 training steps: 0.24609473014525723\n",
      "Training loss per 100 training steps: 0.2438839038385326\n",
      "Training loss per 100 training steps: 0.24283491723459735\n",
      "Training loss per 100 training steps: 0.24160036337842544\n",
      "Training loss per 100 training steps: 0.24054505862409906\n",
      "Training loss per 100 training steps: 0.23821099254524994\n",
      "Training loss per 100 training steps: 0.23720550338108806\n",
      "Training loss per 100 training steps: 0.2357821441310095\n",
      "Training loss per 100 training steps: 0.2353172525108737\n",
      "Training loss per 100 training steps: 0.23412438379718592\n",
      "Training loss per 100 training steps: 0.23331917266336152\n",
      "Training loss per 100 training steps: 0.23278788969470324\n",
      "Training loss per 100 training steps: 0.2317940549090201\n",
      "Training loss per 100 training steps: 0.2299805953359034\n",
      "Training loss per 100 training steps: 0.2284125182769943\n",
      "Training loss per 100 training steps: 0.2274163836427802\n",
      "Training loss per 100 training steps: 0.22709895350031223\n",
      "Training loss per 100 training steps: 0.22648881099999502\n",
      "Training loss per 100 training steps: 0.2267390002989024\n",
      "Training loss per 100 training steps: 0.2259851347572182\n",
      "Training loss per 100 training steps: 0.22480387516802267\n",
      "Training loss per 100 training steps: 0.22364534239527256\n",
      "Training loss per 100 training steps: 0.22303947808357855\n",
      "Training loss per 100 training steps: 0.22316898055105772\n",
      "Training loss per 100 training steps: 0.2226899652680235\n",
      "Training loss per 100 training steps: 0.22194766539534086\n",
      "Training loss per 100 training steps: 0.22178481605861805\n",
      "Training loss per 100 training steps: 0.22038048099741184\n",
      "Training loss per 100 training steps: 0.220839178391384\n",
      "Training loss per 100 training steps: 0.22035368455441598\n",
      "Training loss per 100 training steps: 0.2198425610718673\n",
      "Training loss per 100 training steps: 0.21904287529353844\n",
      "Training loss per 100 training steps: 0.21817304400794105\n",
      "Training loss per 100 training steps: 0.21782159076438304\n",
      "Training loss per 100 training steps: 0.21639390699820535\n",
      "Training loss per 100 training steps: 0.21519547026039892\n",
      "Training loss per 100 training steps: 0.21468121353629965\n",
      "Training loss per 100 training steps: 0.21501293259118007\n",
      "Training loss per 100 training steps: 0.2140083291801765\n",
      "Training loss per 100 training steps: 0.2135013999687245\n",
      "Training loss per 100 training steps: 0.21317379183321328\n",
      "Training loss per 100 training steps: 0.21308534339758944\n",
      "Training loss per 100 training steps: 0.21285240110587292\n",
      "Training loss per 100 training steps: 0.21333823416546846\n",
      "Training loss per 100 training steps: 0.2129505110424369\n",
      "Training loss epoch: 0.21284084051040075\n",
      "Training accuracy epoch: 0.9362322648449816\n"
     ]
    }
   ],
   "source": [
    "# I train the model\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATING THE MODEL\n",
    "Now that the model is trained, I can evaluate its performance on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['input_ids'].type(torch.LongTensor) \n",
    "            mask = batch['attention_mask'].type(torch.LongTensor) \n",
    "            labels = batch['labels'].type(torch.LongTensor) \n",
    "\n",
    "            output = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            eval_loss = output.loss.item()\n",
    "            eval_logits = output.logits\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) \n",
    "            active_logits = eval_logits.view(-1, model.num_labels) \n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) \n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 \n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.0063634030520915985\n",
      "Validation loss per 100 evaluation steps: 0.0004289521291704461\n",
      "Validation loss per 100 evaluation steps: 1.258382443987315e-05\n",
      "Validation loss per 100 evaluation steps: 4.379446324319934e-05\n",
      "Validation loss per 100 evaluation steps: 0.00019018653027731878\n",
      "Validation loss per 100 evaluation steps: 6.398486769098246e-06\n",
      "Validation loss per 100 evaluation steps: 4.183894609056178e-06\n",
      "Validation loss per 100 evaluation steps: 1.0171861981656854e-05\n",
      "Validation loss per 100 evaluation steps: 8.204177524266617e-05\n",
      "Validation loss per 100 evaluation steps: 0.0001842252719944775\n",
      "Validation loss per 100 evaluation steps: 2.630802753430742e-06\n",
      "Validation loss per 100 evaluation steps: 0.00016747631613067018\n",
      "Validation loss per 100 evaluation steps: 4.922374416077564e-06\n",
      "Validation loss per 100 evaluation steps: 3.5880071946421923e-06\n",
      "Validation loss per 100 evaluation steps: 0.00027557577855411724\n",
      "Validation loss per 100 evaluation steps: 1.5980750818716375e-06\n",
      "Validation loss per 100 evaluation steps: 3.3244783806845517e-06\n",
      "Validation loss per 100 evaluation steps: 2.8244894806039398e-06\n",
      "Validation loss per 100 evaluation steps: 2.2790820825470612e-06\n",
      "Validation loss per 100 evaluation steps: 4.163065798843239e-06\n",
      "Validation loss per 100 evaluation steps: 2.0301973410900206e-06\n",
      "Validation loss per 100 evaluation steps: 2.259723017650919e-06\n",
      "Validation loss per 100 evaluation steps: 4.6538277912118225e-06\n",
      "Validation loss per 100 evaluation steps: 8.63878144641795e-06\n",
      "Validation loss per 100 evaluation steps: 1.2064427882122627e-05\n",
      "Validation loss per 100 evaluation steps: 9.917989611530342e-07\n",
      "Validation loss per 100 evaluation steps: 1.6395464863217093e-06\n",
      "Validation loss per 100 evaluation steps: 9.097380136746205e-05\n",
      "Validation loss per 100 evaluation steps: 5.133748613098441e-06\n",
      "Validation loss per 100 evaluation steps: 1.0922211500045883e-06\n",
      "Validation loss per 100 evaluation steps: 1.41626403917475e-06\n",
      "Validation loss per 100 evaluation steps: 2.2321081726599492e-05\n",
      "Validation loss per 100 evaluation steps: 6.9003379957558995e-06\n",
      "Validation loss per 100 evaluation steps: 0.00020022549003732815\n",
      "Validation loss per 100 evaluation steps: 1.3102833986702964e-05\n",
      "Validation loss per 100 evaluation steps: 2.2847038342318717e-05\n",
      "Validation loss per 100 evaluation steps: 1.2083333404618347e-05\n",
      "Validation loss per 100 evaluation steps: 0.0007540003991197876\n",
      "Validation loss per 100 evaluation steps: 6.278979983322873e-07\n",
      "Validation loss per 100 evaluation steps: 1.997891999733384e-05\n",
      "Validation loss per 100 evaluation steps: 3.73600178831847e-06\n",
      "Validation loss per 100 evaluation steps: 0.0002197042467302882\n",
      "Validation loss per 100 evaluation steps: 6.480126290754374e-07\n",
      "Validation loss per 100 evaluation steps: 3.411892998138158e-06\n",
      "Validation loss per 100 evaluation steps: 2.5558720709545672e-06\n",
      "Validation loss per 100 evaluation steps: 3.098883355519317e-05\n",
      "Validation loss per 100 evaluation steps: 2.724857232902807e-05\n",
      "Validation loss per 100 evaluation steps: 1.3608017520710804e-06\n",
      "Validation Loss: 1.1109018105906249e-06\n",
      "Validation Accuracy: 0.9484969518604163\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall performance is good. Accuracy is 94.84%\n",
    "However this statistic could be misleading as a lot of labels are \"outside\" (O). That is, the prediction is biased towards the most popular class in the training set.\n",
    "We can rely on other metrics, such as precision, recall and f1-score of the individual tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9484969518604163\n",
      "Precision: 0.9484969518604163\n",
      "f1 score: 0.9484969518604163\n",
      "----------------------------\n",
      "[[ 564    6   43   21    0    8]\n",
      " [  52  520   14    0    0    5]\n",
      " [ 107    4  331   37    0   51]\n",
      " [   9    2   32  726    0   22]\n",
      " [   1    0    0    0   90   14]\n",
      " [   5    4   44    7    2 6793]]\n"
     ]
    }
   ],
   "source": [
    "recall_val = recall_score(y_true = labels, y_pred =predictions, average= 'micro')\n",
    "print(f'Recall: {recall_val}')\n",
    "\n",
    "precision_val = precision_score(y_true = labels, y_pred =predictions, average= 'micro')\n",
    "print(f'Precision: {precision_val}')\n",
    "\n",
    "f1_val = f1_score(y_true = labels, y_pred =predictions, average= 'micro')\n",
    "print(f'f1 score: {f1_val}')\n",
    "\n",
    "print('----------------------------')\n",
    "lab = numpy.unique(labels)\n",
    "print(confusion_matrix(y_true = labels, y_pred =predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, these metrics confirm that the model performs quite good.\n",
    "Obviously better performances could be achieved evaluating the training step by step over a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST\n",
    "Now that we have a final model, trained and evaluated with overall good performances, it is possible to use it directly on unseen sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': ['[CLS]', '.', '.', 'ha', 'di', '##chia', '##rat', '##o', 'quan', '##to', 'se', '##gue', '.', 'con', 'la', 'decision', '##e', 'in', 'ep', '##ig', '##raf', '##e', ',', 'la', '##rte', 'd', \"'\", 'ha', 'con', '##fer', '##mat', '##o', 'la', 'sent', '##en', '##za', 'del', 'tribunal', '##e', 'del', '30', '.', '10', '.', '2017', 'con', 'cu', '##i', '.', '.', 'e', 'stat', '##a', 'con', '##dan', '##nat', '##a', 'alla', 'pena', 'di', '15', '##orn', '##i', 'di', 'rec', '##lusion', '##e', 'in', 're', '##la', '##zione', 'al', 're', '##ato', 'di', '##i', 'all', \"'\", 'art', '.', '61', '##5', '-', 'ter', 'c', '.', '.', ',', 'per', 'ave', '##r', 'mod', '##ific', '##ato', 'ed', 'ut', '##ili', '##to', 'la', 'password', 'di', 'access', '##o', 'al', '##etto', 'fiscal', '##e', '[SEP]'], 'B-per': ['la', 'c', 'cost', 'app', '##ello', 'napoli', 'g', 'a', 'gi', 'cu', 'p', '##zza', 'cass', 'della', 'sore', '##lla'], 'B-org': ['co', 'di', 'di', 'torino']}\n"
     ]
    }
   ],
   "source": [
    "# Some inference\n",
    "\n",
    "sentence = '''  La C. cost. ha dichiarato quanto segue.\n",
    "            Con la decisione in epigrafe, la Corte d'Appello di Napoli ha confermato la \n",
    "            sentenza del Tribunale di Torino del 30.10.2017 con cui G.A. è stata condannata alla \n",
    "            pena di 15 giorni di reclusione in relazione al reato di cui all'art. 615-ter c.p., per aver \n",
    "            modificato ed utilizzato la password di accesso al cassetto fiscale della sorella L., \n",
    "            aperto presso l'Agenzia delle Entrate, al fine di continuare a gestire il patrimonio \n",
    "            familiare pur dopo la cessazione della delega ad agire per conto di costei e i dissidi \n",
    "            insorti tra loro (in particolare, per registrare le locazioni relative agli immobili di \n",
    "            famiglia).'''\n",
    "\n",
    "inputs = tokenizer(sentence,\n",
    "                    # is_pretokenized=True, \n",
    "                    return_offsets_mapping=True, \n",
    "                    padding='max_length', \n",
    "                    truncation=True, \n",
    "                    max_length=MAX_LEN,\n",
    "                    return_tensors=\"pt\")\n",
    "\n",
    "ids = inputs[\"input_ids\"]\n",
    "mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model(ids, attention_mask=mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) \n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) \n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "label_dict = {}\n",
    "\n",
    "# Iterate over the list of tuples\n",
    "for word, label in wp_preds:\n",
    "    # If the label is already a key in the dictionary, append the word to its list\n",
    "    if label in label_dict:\n",
    "        label_dict[label].append(word)\n",
    "    # If the label is not a key in the dictionary, create a new list with the word\n",
    "    else:\n",
    "        label_dict[label] = [word]\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label O : ['[CLS]', '.', '.', 'ha', 'di', '##chia', '##rat', '##o', 'quan', '##to', 'se', '##gue', '.', 'con', 'la', 'decision', '##e', 'in', 'ep', '##ig', '##raf', '##e', ',', 'la', '##rte', 'd', \"'\", 'ha', 'con', '##fer', '##mat', '##o', 'la', 'sent', '##en', '##za', 'del', 'tribunal', '##e', 'del', '30', '.', '10', '.', '2017', 'con', 'cu', '##i', '.', '.', 'e', 'stat', '##a', 'con', '##dan', '##nat', '##a', 'alla', 'pena', 'di', '15', '##orn', '##i', 'di', 'rec', '##lusion', '##e', 'in', 're', '##la', '##zione', 'al', 're', '##ato', 'di', '##i', 'all', \"'\", 'art', '.', '61', '##5', '-', 'ter', 'c', '.', '.', ',', 'per', 'ave', '##r', 'mod', '##ific', '##ato', 'ed', 'ut', '##ili', '##to', 'la', 'password', 'di', 'access', '##o', 'al', '##etto', 'fiscal', '##e', '[SEP]']\n",
      "Label B-per : ['la', 'c', 'cost', 'app', '##ello', 'napoli', 'g', 'a', 'gi', 'cu', 'p', '##zza', 'cass', 'della', 'sore', '##lla']\n",
      "Label B-org : ['co', 'di', 'di', 'torino']\n"
     ]
    }
   ],
   "source": [
    "# For each label, I get the list of words or word-pieces associated to it\n",
    "for label, elements in label_dict.items():\n",
    "    printed_labels = []\n",
    "    if label not in printed_labels:\n",
    "        elenco = label_dict[f'{label}']\n",
    "        print(f\"Label {label} : {elenco}\") \n",
    "        printed_labels.append(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MinisteroGiustiziaLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
